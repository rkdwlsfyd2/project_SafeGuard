import React, { useState, useEffect, useRef } from 'react';
import { useNavigate } from 'react-router-dom';
import { complaintsAPI, sttAPI, getToken, analyzeText } from '../utils/api';

function ApplyVoice() {
    const navigate = useNavigate();
    const mapRef = useRef(null);

    const [formData, setFormData] = useState({
        title: '',
        content: '',
        isPublic: true,
        location: {
            lat: 37.5665,
            lng: 126.9780,
            address: 'ì„œìš¸íŠ¹ë³„ì‹œ ì¤‘êµ¬'
        }
    });

    const [loading, setLoading] = useState(false);
    const [error, setError] = useState('');
    const [currentStep, setCurrentStep] = useState(1);
    const [isAnalyzing, setIsAnalyzing] = useState(false);
    const [ragResult, setRagResult] = useState(null);

    // ğŸ¤ Recording state
    const [isRecording, setIsRecording] = useState(false);
    const [recordingTime, setRecordingTime] = useState(0);
    const mediaRecorderRef = useRef(null);
    const chunksRef = useRef([]);
    const recognitionRef = useRef(null);

    /** â±ï¸ ë…¹ìŒ íƒ€ì´ë¨¸ */
    useEffect(() => {
        let timer;
        if (isRecording) {
            timer = setInterval(() => {
                setRecordingTime(prev => prev + 1);
            }, 1000);
        }
        return () => clearInterval(timer);
    }, [isRecording]);

    /** ğŸ—£ï¸ ë¸Œë¼ìš°ì € ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ (ë¯¸ë¦¬ë³´ê¸°ìš©) */
    useEffect(() => {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!SpeechRecognition) return;

        const recognition = new SpeechRecognition();
        recognition.lang = 'ko-KR';
        recognition.continuous = true;
        recognition.interimResults = true;

        recognition.onresult = (event) => {
            let transcript = '';
            for (let i = event.resultIndex; i < event.results.length; i++) {
                transcript += event.results[i][0].transcript;
            }

            if (transcript) {
                setFormData(prev => ({ ...prev, content: transcript }));
            }
        };

        recognitionRef.current = recognition;
    }, []);

    /** ğŸ¤ ë…¹ìŒ ì‹œì‘ / ì¢…ë£Œ */
    const handleToggleRecord = async () => {
        if (isRecording) {
            // â›” STOP
            mediaRecorderRef.current.stop();
            setIsRecording(false);
            return;
        }

        // â–¶ START
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

            const mediaRecorder = new MediaRecorder(stream, {
                mimeType: 'audio/webm'   // â­ ì¤‘ìš”
            });

            mediaRecorderRef.current = mediaRecorder;
            chunksRef.current = [];

            mediaRecorder.ondataavailable = (e) => {
                if (e.data.size > 0) chunksRef.current.push(e.data);
            };

            mediaRecorder.onstop = async () => {
                // ğŸ›‘ SpeechRecognition ì™„ì „ ì¢…ë£Œ (ë®ì–´ì“°ê¸° ë°©ì§€)
                if (recognitionRef.current) {
                    recognitionRef.current.onresult = null;
                    recognitionRef.current.stop();
                }

                const audioBlob = new Blob(chunksRef.current, { type: 'audio/webm' });

                setLoading(true);
                setError('');

                try {
                    const result = await sttAPI.transcribe(audioBlob);
                    if (result?.stt_text) {
                        setFormData(prev => ({
                            ...prev,
                            content: result.stt_text
                        }));
                    }
                } catch (err) {
                    setError('ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ' + err.message);
                } finally {
                    setLoading(false);
                    stream.getTracks().forEach(t => t.stop());
                }
            };

            setFormData(prev => ({ ...prev, content: '' }));
            mediaRecorder.start();
            recognitionRef.current?.start();

            setRecordingTime(0);
            setIsRecording(true);

        } catch (err) {
            console.error(err);
            setError('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
        }
    };

    /** â±ï¸ ì‹œê°„ í‘œì‹œ */
    const formatTime = (sec) => {
        const m = Math.floor(sec / 60);
        const s = sec % 60;
        return `${m}:${s.toString().padStart(2, '0')}`;
    };

    /** ë‹¨ê³„ í‘œì‹œ */
    useEffect(() => {
        if (formData.title) setCurrentStep(2);
        if (formData.title && formData.content) setCurrentStep(3);
        if (formData.title && formData.content && formData.location.address) setCurrentStep(4);
    }, [formData]);

    /** ğŸ¤– RAG ë¶„ì„ */
    const handleAnalyze = async () => {
        if (!formData.content) return;
        setIsAnalyzing(true);
        try {
            const result = await analyzeText(formData.content);
            setRagResult(result);
        } catch (err) {
            setError('AI ë¶„ì„ ì‹¤íŒ¨: ' + err.message);
        } finally {
            setIsAnalyzing(false);
        }
    };

    /** ğŸš€ ë¯¼ì› ì œì¶œ */
    const handleSubmit = async (e) => {
        e.preventDefault();

        if (!getToken()) {
            alert('ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.');
            navigate('/login');
            return;
        }

        if (!formData.title || !formData.content) {
            setError('ì œëª©ê³¼ ìŒì„± ì¸ì‹ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.');
            return;
        }

        setLoading(true);
        setError('');

        try {
            const res = await complaintsAPI.create({
                category: 'ìŒì„±',
                title: formData.title,
                content: formData.content,
                isPublic: formData.isPublic,
                location: formData.location
            });

            alert(`ìŒì„± ë¯¼ì›ì´ ì ‘ìˆ˜ë˜ì—ˆìŠµë‹ˆë‹¤. (ì ‘ìˆ˜ë²ˆí˜¸: ${res.complaintNo})`);
            navigate('/list');
        } catch (err) {
            setError(err.message);
        } finally {
            setLoading(false);
        }
    };

    return (
        <div style={{ padding: '40px' }}>
            <h1>ğŸ™ï¸ ìŒì„± ë¯¼ì› ì‹ ì²­</h1>

            {error && <div style={{ color: 'red' }}>{error}</div>}

            <input
                placeholder="ë¯¼ì› ì œëª©"
                value={formData.title}
                onChange={e => setFormData(p => ({ ...p, title: e.target.value }))}
            />

            <div style={{ margin: '20px 0' }}>
                <button onClick={handleToggleRecord}>
                    {isRecording ? `â¹ ${formatTime(recordingTime)}` : 'ğŸ¤ ë…¹ìŒ ì‹œì‘'}
                </button>
            </div>

            <textarea
                rows={6}
                value={formData.content}
                onChange={e => setFormData(p => ({ ...p, content: e.target.value }))}
                placeholder="ìŒì„± ì¸ì‹ ê²°ê³¼"
            />

            <div style={{ marginTop: 10 }}>
                <button type="button" onClick={handleAnalyze} disabled={isAnalyzing}>
                    {isAnalyzing ? 'ë¶„ì„ ì¤‘...' : 'ğŸ¤– AI ë¶„ì„'}
                </button>
            </div>

            <button onClick={handleSubmit} disabled={loading}>
                {loading ? 'ì ‘ìˆ˜ ì¤‘...' : 'ğŸš€ ë¯¼ì› ì ‘ìˆ˜'}
            </button>
        </div>
    );
}
export default ApplyVoice